name: Build, Push Docker Image & Deploy Kubernetes Cluster

on:
  push:
    branches:
      - main
 

env:
  LOCAL_IMAGE_NAME: web-app
  ECR_REPO_NAME: my-ecr-repo
  IMAGE_TAG: latest

jobs:
 
  terraform-and-build:
    runs-on: ubuntu-latest
    outputs:
      TERRAFORM_ECR_URI: ${{ steps.tf_output.outputs.TERRAFORM_ECR_URI }}
      MASTER_IP: ${{ steps.tf_output.outputs.MASTER_IP }}
      WORKER_IPS: ${{ steps.tf_output.outputs.WORKER_IPS }}
    steps:
      - name: Checkout source code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init and Import Existing Resources
        working-directory: ./Terraform
        run: |
          terraform init || terraform init -reconfigure

        
          terraform import aws_key_pair.mykeyname mykeyname || echo "→ Already managed or not found"

          echo "Importing ECR repository..."
          terraform import aws_ecr_repository.my_ecr_repo my-ecr-repo || echo "→ Already managed"

          echo "Importing IAM role..."
          terraform import aws_iam_role.ec2_cloudwatch_role ec2_cloudwatch_role || echo "→ Already managed"

          echo "Importing IAM instance profile..."
          terraform import aws_iam_instance_profile.ec2_cloudwatch_profile ec2_cloudwatch_profile || echo "→ Already managed"

      - name: Terraform Apply (No-op if no changes)
        working-directory: ./Terraform
        run: terraform apply -auto-approve

      - name: Export Terraform Outputs
        id: tf_output
        run: |
        
          cd $GITHUB_WORKSPACE

          ECR_URI=$(terraform -chdir=./Terraform output -raw ecr_uri)
          MASTER_IP=$(terraform -chdir=./Terraform output -raw master_public_ip)
          WORKER_IPS=$(terraform -chdir=./Terraform output -json worker_public_ips)

          echo "TERRAFORM_ECR_URI=$ECR_URI" >> "$GITHUB_OUTPUT"
          echo "MASTER_IP=$MASTER_IP" >> "$GITHUB_OUTPUT"
          echo "WORKER_IPS=$WORKER_IPS" >> "$GITHUB_OUTPUT"


  dockerbuild-push:
    runs-on: ubuntu-latest
    needs: terraform-and-build
    steps:
      - name: Checkout source code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to ECR
        env:
          ECR_URI: ${{ needs.terraform-and-build.outputs.TERRAFORM_ECR_URI }}
        run: |
          aws ecr get-login-password --region ${{ secrets.AWS_REGION }} \
            | docker login --username AWS --password-stdin $ECR_URI

      - name: Build Docker Image
        run: |
          docker build -t $LOCAL_IMAGE_NAME ./app

      - name: Tag and Push to ECR
        env:
          ECR_URI: ${{ needs.terraform-and-build.outputs.TERRAFORM_ECR_URI }}
        run: |
          docker tag $LOCAL_IMAGE_NAME:latest $ECR_URI:$IMAGE_TAG
          docker push $ECR_URI:$IMAGE_TAG

 
  ansible_deploy:
    needs: dockerbuild-push
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Ansible & Dependencies
        run: |
          sudo yum update -y
          sudo yum install -y sshpass jq nmap-ncat
          pip3 install --user ansible boto3
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Add SSH Private Key
        uses: ssh-action/setup-ssh@v0.2.0
        with:
          host: ${{ needs.terraform-and-build.outputs.MASTER_IP }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          known_hosts_required: false
          ssh_config: |
            Host *
              StrictHostKeyChecking no
              UserKnownHostsFile=/dev/null

      - name: Create Ansible Inventory
        run: |
          MASTER_IP="${{ needs.terraform-and-build.outputs.MASTER_IP }}"
          WORKER_IPS='${{ needs.terraform-and-build.outputs.WORKER_IPS }}'

          echo "[master]" > inventory.ini
          echo "$MASTER_IP ansible_user=ec2-user ansible_ssh_private_key_file=~/.ssh/id_rsa ansible_python_interpreter=/usr/bin/python3.8" >> inventory.ini

          echo "[workers]" >> inventory.ini
          echo "$WORKER_IPS" | jq -r '.[]' | while read ip; do
            echo "$ip ansible_user=ec2-user ansible_ssh_private_key_file=~/.ssh/id_rsa ansible_python_interpreter=/usr/bin/python3.8" >> inventory.ini
          done

          echo "[all:children]" >> inventory.ini
          echo "master" >> inventory.ini
          echo "workers" >> inventory.ini

          cat inventory.ini

      - name: Wait for SSH Access
        run: |
          set +e
          for i in {1..12}; do
            ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no \
                -i ~/.ssh/id_rsa ec2-user@${{ needs.terraform-and-build.outputs.MASTER_IP }} \
                echo "SSH is UP" && exit 0
            echo "Waiting for SSH... (attempt $i/12)"
            sleep 10
          done
          echo "SSH connection failed after 12 attempts"
          exit 1
        shell: bash

      - name: Run Master Playbook
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          ansible-playbook -i inventory.ini ./Ansible/master.yml

      - name: Run Worker Playbook
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          ansible-playbook -i inventory.ini ./Ansible/worker.yml